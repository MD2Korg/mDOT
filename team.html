<!DOCTYPE HTML>
<!--
	Frequency by Pixelarity
	pixelarity.com | hello@pixelarity.com
	License: pixelarity.com/license
-->
<html>
	<head>
		<title>mDOT - Team</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body>

		<!-- Header -->
			<header id="header">
				<h1 id="logo"><a href="index.html">mDOT</a></h1>
				<nav id="nav">
					<ul>
						<li><a href="index3.html">Home</a></li>
						<li>
							<a href="index3.html#one">About</a>
							<ul>
								<li><a href="vision.html">Vision</a></li>
								<li><a href="innovation.html">Innovation & Impact</a></li>
								<li><a href="team.html">Team</a></li>
								<li><a href="index3.html#contact">Contact</a></li>
								<!-- <li>
									<a href="#">Submenu</a>
									<ul>
										<li><a href="#">Option 1</a></li>
										<li><a href="#">Option 2</a></li>
										<li><a href="#">Option 3</a></li>
										<li><a href="#">Option 4</a></li>
									</ul>
								</li> -->
							</ul>
						</li>
						<li><a href="trdhome.html">TR&D Research</a>
							<ul>
								<li><a href="trd1.html">TR&D1 Discovery</a></li>
								<li><a href="trd2.html">TR&D2 Optimization</a></li>
								<li><a href="trd3.html">TR&D3 Translation</a></li>
							</ul>
						</li>
						<li><a href="cps.html">Collaborative Projects</a></li>
						<li><a href="sps.html">Service Projects</a></li>
						<li><a href="training.html">Training</a></li>
					</ul>
				</nav>
			</header>

		<!-- Main -->
			<section id="main" class="wrapper style1">
				<div class="container box big bordered">
					<header class="major special" style="margin-bottom: 0;">
						<h2>Organizational Structure</h2>
							<a href="images/mDOTorgchart2.jpg" target="_blank"><img src="images/mDOTorgchart2.jpg" alt="" style="width: 100%; padding: 10px; margin-bottom: 10px;" /></a>
							<p style="font-size: 0.9em; margin-bottom: 8em;">mDOT is headquartered at the University of Memphis in collaboration with these universities: Georgia Institute of Technology, Harvard University, University of Massachusetts at Amherst, The Ohio State University, University of California Los Angeles, and University of California San Francisco.</p>
						<h2>Meet the Team</h2>
	<!--					<p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p> -->
					</header>

					<!-- Content -->
						<section id="content">
							<!-- <a href="#" class="image main"><img src="images/pic04.jpg" alt="" /></a> -->


							<h3>Santosh Kumar, Ph.D.</h3>
							<h4>Lead PI, Center Director, TR&amp;D1, TR&amp;D2, TR&amp;D3</h4>
							<div style="float: left; padding: 25px;">
								<p><img src="images/team/Kumar_Santosh.png" alt="Santosh Kumar" style="width: 150px; border-radius: 4px; border: 1px solid #ddd; padding: 5px; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);" /></p>
								<p><img src="images/team/memphis-logo.png" alt="University of Memphis" width="150px" /></p>
							</div>
							<p style="text-align: justify;">Dr. Kumar is the Lillian and Morrie Moss Chair of Excellence Professor in the Department of Computer Science at the University of Memphis and the Director of the NIH Center of Excellence for Mobile Sensor Data-to-Knowledge (MD2K), which is headquartered at the University of Memphis. He received his Ph.D. in Computer Science and Engineering from The Ohio State University in 2006, where his dissertation won a presidential fellowship. In 2010, Popular Science magazine named him one of America&rsquo;s ten most brilliant scientists under the age of 38 (called &ldquo;Brilliant Ten&rdquo;). In 2011, he chaired the &ldquo;mHealth Evidence&rdquo; meeting jointly organized by NIH, NSF, RWJF, and McKesson Foundation to establish evidence requirements for mHealth. In 2013, he was invited to meet with the NIH Director to advise him on NIH efforts in the area of mHealth and was invited to the White House to give a talk on the future of Biosensors. In 2014, he co-organized and co-chaired the NSF-NIH Workshop on Computing Challenges in Future Mobile Health (mHealth) Systems and Applications. He holds the distinction of receiving the largest grants from both NIH ($10.8 million in 2014) and NSF ($4 million In 2016) in the history of the University of Memphis. Santosh&rsquo;s research seeks to define new frontiers in the newly-emerging discipline of mobile health (mHealth). His decade-long work has involved collecting mobile sensor data from over 100 human volunteers for 25,000+ hours in their natural environments as part of various scientific user studies. His collaborative research involves more than twenty faculty members from fifteen institutions, spanning a variety of disciplines, making his projects highly transdisciplinary.</p>
							<hr style="color: #eb4947; width: 90%; size: 1.5px;" />

							<h3>James Rehg, Ph.D.</h3>
							<h4>Deputy Center Director, TR&amp;D1 Lead</h4>
							<div style="float: left; padding: 25px;">
								<p><img src="images/team/Jim_Rehg.png" alt="Jim Rehg" style="width: 150px; border-radius: 4px; border: 1px solid #ddd; padding: 5px; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);" /></p>
								<p><img src="images/team/GeorgiaTech.png" alt="Georgia Tech" width="150px" /></p>
							</div>
							<p style="text-align: justify;">Dr. Rehg (pronounced 'ray") is a Professor in the School of Interactive Computing at the Georgia Institute of Technology, where he is co-Director of the Computational Perception Lab (CPL) and Director of the Center for Behavioral Imaging. He received his Ph.D. from CMU in 1995 and worked at the Cambridge Research Lab of DEC (and then Compaq) from 1995-2001, where he managed the computer vision research group. He received an NSF CAREER award in 2001 and a Raytheon Faculty Fellowship from Georgia Tech in 2005. He and his students have received best student paper awards at ICML 2005, BMVC 2010, Mobihealth 2014, and Face and Gesture 2015, and a 2013 Method of the Year Award from the journal Nature Methods. Dr. Rehg serves on the Editorial Board of the Intl. J. of Computer Vision, and he served as the Program co-Chair for ACCV 2012 and General co-Chair for CVPR 2009, and will serve as Program co-Chair for CVPR 2017. He has authored more than 100 peer-reviewed scientific papers and holds 25 issued US patents. His research interests include computer vision, machine learning, pattern recognition, and robot perception. Dr. Rehg is the lead PI on an NSF Expedition to develop the science and technology of Behavioral Imaging, the measurement and analysis of social and communicative behavior using multi-modal sensing, with applications to developmental disorders such as autism. He also serves as the Deputy Director of the NIH Center of Excellence on Mobile Sensor Data-to-Knowledge (MD2K).</p>
							<hr style="color: #eb4947; width: 90%; size: 1.5px;" />

							<h3>Susan Murphy, Ph.D.</h3>
							<h4>TR&amp;D2 Lead</h4>
							<div style="float: left; padding: 25px;">
								<p><img src="images/team/Murphy.png" alt="Jim Rehg" style="width: 150px; border-radius: 4px; border: 1px solid #ddd; padding: 5px; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);" /></p>
								<p><img src="images/team/harvard.png" alt="Georgia Tech" width="150px" /></p>
							</div>
							<p style="text-align: justify;">Dr. Murphy is the Professor of Statistics and Computer Science, and the Radcliffe Alumnae Professor at the Radcliffe Institute, Harvard University. She directs the Statistical Reinforcement Learning Lab at Harvard University. Her research concerns clinical trial design and the development of data analytic methods for informing multi-stage decision making in health. In particular for (1) constructing individualized sequences of treatments (a.k.a., adaptive interventions) for use in informing clinical decision making and (2) constructing real-time individualized sequences of treatments (a.k.a., Just-in-Time Adaptive Interventions) delivered by mobile devices. Murphy has developed a formal model of this decision-making process and an innovative design for clinical trials called Sequential Multiple Assignment Randomized Trial (SMART) that allow researchers to optimize adaptive interventions. In 2016, she was elected a member of the National Academy of Sciences, in 2014, she was elected a member of the National Academy of Medicine, and in 2013, she was selected as a MacArthur Fellow.</p>
							<hr style="color: #eb4947; width: 90%; size: 1.5px;" />

							<h3>Benjamin Marlin, Ph.D.</h3>
							<h4>Co-I, TR&amp;D1, TR&amp;D2</h4>
							<div style="float: left; padding: 25px;">
								<p><img src="images/team/Marlin.png" alt="Jim Rehg" style="width: 150px; border-radius: 4px; border: 1px solid #ddd; padding: 5px; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);" /></p>
								<p><img src="images/team/UMass.png" alt="Georgia Tech" width="150px" /></p>
							</div>
							<p style="text-align: justify;">Dr. Marlin joined the College of Information and Computer Sciences at the University of Massachusetts Amherst in 2011. There, he co-directs the Machine Learning for Data Science lab. His current research centers on the development of customized probabilistic models and algorithms for time series with applications to the analysis of electronic health records and mobile health data. His recent work includes probabilistic models for analyzing wireless ECG data, detection of cocaine use from wireless ECG, hierarchical activity recognition from on-body sensor data with applications to smoking and eating detection, and methods for mitigating lab-to-field generalization loss in mobile health studies. Marlin is a 2014 NSF CAREER award recipient and a 2013 Yahoo! Faculty Research Engagement Program award recipient. His research has also been supported by the National Institutes of Health, the Patient-Centered Outcomes Research Institute, and the US Army Research Laboratory. Prior to joining UMass Amherst, Marlin was a fellow of the Pacific Institute for the Mathematical Sciences and the Killam Trusts at the University of British Columbia. He completed his PhD in machine learning in the Department of Computer Science at the University of Toronto.</p>
							<hr style="color: #eb4947; width: 90%; size: 1.5px;" />

							<h3>James Rehg, Ph.D.</h3>
							<h4>Deputy Center Director, TR&amp;D1 Lead</h4>
							<div style="float: left; padding: 25px;">
								<p><img src="images/team/Jim_Rehg.png" alt="Jim Rehg" style="width: 150px; border-radius: 4px; border: 1px solid #ddd; padding: 5px; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);" /></p>
								<p><img src="images/team/GeorgiaTech.png" alt="Georgia Tech" width="150px" /></p>
							</div>
							<p style="text-align: justify;">Dr. Rehg (pronounced 'ray") is a Professor in the School of Interactive Computing at the Georgia Institute of Technology, where he is co-Director of the Computational Perception Lab (CPL) and Director of the Center for Behavioral Imaging. He received his Ph.D. from CMU in 1995 and worked at the Cambridge Research Lab of DEC (and then Compaq) from 1995-2001, where he managed the computer vision research group. He received an NSF CAREER award in 2001 and a Raytheon Faculty Fellowship from Georgia Tech in 2005. He and his students have received best student paper awards at ICML 2005, BMVC 2010, Mobihealth 2014, and Face and Gesture 2015, and a 2013 Method of the Year Award from the journal Nature Methods. Dr. Rehg serves on the Editorial Board of the Intl. J. of Computer Vision, and he served as the Program co-Chair for ACCV 2012 and General co-Chair for CVPR 2009, and will serve as Program co-Chair for CVPR 2017. He has authored more than 100 peer-reviewed scientific papers and holds 25 issued US patents. His research interests include computer vision, machine learning, pattern recognition, and robot perception. Dr. Rehg is the lead PI on an NSF Expedition to develop the science and technology of Behavioral Imaging, the measurement and analysis of social and communicative behavior using multi-modal sensing, with applications to developmental disorders such as autism. He also serves as the Deputy Director of the NIH Center of Excellence on Mobile Sensor Data-to-Knowledge (MD2K).</p>
							<hr style="color: #eb4947; width: 90%; size: 1.5px;" />

							<h3>James Rehg, Ph.D.</h3>
							<h4>Deputy Center Director, TR&amp;D1 Lead</h4>
							<div style="float: left; padding: 25px;">
								<p><img src="images/team/Jim_Rehg.png" alt="Jim Rehg" style="width: 150px; border-radius: 4px; border: 1px solid #ddd; padding: 5px; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);" /></p>
								<p><img src="images/team/GeorgiaTech.png" alt="Georgia Tech" width="150px" /></p>
							</div>
							<p style="text-align: justify;">Dr. Rehg (pronounced 'ray") is a Professor in the School of Interactive Computing at the Georgia Institute of Technology, where he is co-Director of the Computational Perception Lab (CPL) and Director of the Center for Behavioral Imaging. He received his Ph.D. from CMU in 1995 and worked at the Cambridge Research Lab of DEC (and then Compaq) from 1995-2001, where he managed the computer vision research group. He received an NSF CAREER award in 2001 and a Raytheon Faculty Fellowship from Georgia Tech in 2005. He and his students have received best student paper awards at ICML 2005, BMVC 2010, Mobihealth 2014, and Face and Gesture 2015, and a 2013 Method of the Year Award from the journal Nature Methods. Dr. Rehg serves on the Editorial Board of the Intl. J. of Computer Vision, and he served as the Program co-Chair for ACCV 2012 and General co-Chair for CVPR 2009, and will serve as Program co-Chair for CVPR 2017. He has authored more than 100 peer-reviewed scientific papers and holds 25 issued US patents. His research interests include computer vision, machine learning, pattern recognition, and robot perception. Dr. Rehg is the lead PI on an NSF Expedition to develop the science and technology of Behavioral Imaging, the measurement and analysis of social and communicative behavior using multi-modal sensing, with applications to developmental disorders such as autism. He also serves as the Deputy Director of the NIH Center of Excellence on Mobile Sensor Data-to-Knowledge (MD2K).</p>
							<hr style="color: #eb4947; width: 90%; size: 1.5px;" />

							<h3>James Rehg, Ph.D.</h3>
							<h4>Deputy Center Director, TR&amp;D1 Lead</h4>
							<div style="float: left; padding: 25px;">
								<p><img src="images/team/Jim_Rehg.png" alt="Jim Rehg" style="width: 150px; border-radius: 4px; border: 1px solid #ddd; padding: 5px; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);" /></p>
								<p><img src="images/team/GeorgiaTech.png" alt="Georgia Tech" width="150px" /></p>
							</div>
							<p style="text-align: justify;">Dr. Rehg (pronounced 'ray") is a Professor in the School of Interactive Computing at the Georgia Institute of Technology, where he is co-Director of the Computational Perception Lab (CPL) and Director of the Center for Behavioral Imaging. He received his Ph.D. from CMU in 1995 and worked at the Cambridge Research Lab of DEC (and then Compaq) from 1995-2001, where he managed the computer vision research group. He received an NSF CAREER award in 2001 and a Raytheon Faculty Fellowship from Georgia Tech in 2005. He and his students have received best student paper awards at ICML 2005, BMVC 2010, Mobihealth 2014, and Face and Gesture 2015, and a 2013 Method of the Year Award from the journal Nature Methods. Dr. Rehg serves on the Editorial Board of the Intl. J. of Computer Vision, and he served as the Program co-Chair for ACCV 2012 and General co-Chair for CVPR 2009, and will serve as Program co-Chair for CVPR 2017. He has authored more than 100 peer-reviewed scientific papers and holds 25 issued US patents. His research interests include computer vision, machine learning, pattern recognition, and robot perception. Dr. Rehg is the lead PI on an NSF Expedition to develop the science and technology of Behavioral Imaging, the measurement and analysis of social and communicative behavior using multi-modal sensing, with applications to developmental disorders such as autism. He also serves as the Deputy Director of the NIH Center of Excellence on Mobile Sensor Data-to-Knowledge (MD2K).</p>
							<hr style="color: #eb4947; width: 90%; size: 1.5px;" />

							<h3>James Rehg, Ph.D.</h3>
							<h4>Deputy Center Director, TR&amp;D1 Lead</h4>
							<div style="float: left; padding: 25px;">
								<p><img src="images/team/Jim_Rehg.png" alt="Jim Rehg" style="width: 150px; border-radius: 4px; border: 1px solid #ddd; padding: 5px; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);" /></p>
								<p><img src="images/team/GeorgiaTech.png" alt="Georgia Tech" width="150px" /></p>
							</div>
							<p style="text-align: justify;">Dr. Rehg (pronounced 'ray") is a Professor in the School of Interactive Computing at the Georgia Institute of Technology, where he is co-Director of the Computational Perception Lab (CPL) and Director of the Center for Behavioral Imaging. He received his Ph.D. from CMU in 1995 and worked at the Cambridge Research Lab of DEC (and then Compaq) from 1995-2001, where he managed the computer vision research group. He received an NSF CAREER award in 2001 and a Raytheon Faculty Fellowship from Georgia Tech in 2005. He and his students have received best student paper awards at ICML 2005, BMVC 2010, Mobihealth 2014, and Face and Gesture 2015, and a 2013 Method of the Year Award from the journal Nature Methods. Dr. Rehg serves on the Editorial Board of the Intl. J. of Computer Vision, and he served as the Program co-Chair for ACCV 2012 and General co-Chair for CVPR 2009, and will serve as Program co-Chair for CVPR 2017. He has authored more than 100 peer-reviewed scientific papers and holds 25 issued US patents. His research interests include computer vision, machine learning, pattern recognition, and robot perception. Dr. Rehg is the lead PI on an NSF Expedition to develop the science and technology of Behavioral Imaging, the measurement and analysis of social and communicative behavior using multi-modal sensing, with applications to developmental disorders such as autism. He also serves as the Deputy Director of the NIH Center of Excellence on Mobile Sensor Data-to-Knowledge (MD2K).</p>
							<hr style="color: #eb4947; width: 90%; size: 1.5px;" />

							<h3>James Rehg, Ph.D.</h3>
							<h4>Deputy Center Director, TR&amp;D1 Lead</h4>
							<div style="float: left; padding: 25px;">
								<p><img src="images/team/Jim_Rehg.png" alt="Jim Rehg" style="width: 150px; border-radius: 4px; border: 1px solid #ddd; padding: 5px; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);" /></p>
								<p><img src="images/team/GeorgiaTech.png" alt="Georgia Tech" width="150px" /></p>
							</div>
							<p style="text-align: justify;">Dr. Rehg (pronounced 'ray") is a Professor in the School of Interactive Computing at the Georgia Institute of Technology, where he is co-Director of the Computational Perception Lab (CPL) and Director of the Center for Behavioral Imaging. He received his Ph.D. from CMU in 1995 and worked at the Cambridge Research Lab of DEC (and then Compaq) from 1995-2001, where he managed the computer vision research group. He received an NSF CAREER award in 2001 and a Raytheon Faculty Fellowship from Georgia Tech in 2005. He and his students have received best student paper awards at ICML 2005, BMVC 2010, Mobihealth 2014, and Face and Gesture 2015, and a 2013 Method of the Year Award from the journal Nature Methods. Dr. Rehg serves on the Editorial Board of the Intl. J. of Computer Vision, and he served as the Program co-Chair for ACCV 2012 and General co-Chair for CVPR 2009, and will serve as Program co-Chair for CVPR 2017. He has authored more than 100 peer-reviewed scientific papers and holds 25 issued US patents. His research interests include computer vision, machine learning, pattern recognition, and robot perception. Dr. Rehg is the lead PI on an NSF Expedition to develop the science and technology of Behavioral Imaging, the measurement and analysis of social and communicative behavior using multi-modal sensing, with applications to developmental disorders such as autism. He also serves as the Deputy Director of the NIH Center of Excellence on Mobile Sensor Data-to-Knowledge (MD2K).</p>
							<hr style="color: #eb4947; width: 90%; size: 1.5px;" />

							<h3>James Rehg, Ph.D.</h3>
							<h4>Deputy Center Director, TR&amp;D1 Lead</h4>
							<div style="float: left; padding: 25px;">
								<p><img src="images/team/Jim_Rehg.png" alt="Jim Rehg" style="width: 150px; border-radius: 4px; border: 1px solid #ddd; padding: 5px; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);" /></p>
								<p><img src="images/team/GeorgiaTech.png" alt="Georgia Tech" width="150px" /></p>
							</div>
							<p style="text-align: justify;">Dr. Rehg (pronounced 'ray") is a Professor in the School of Interactive Computing at the Georgia Institute of Technology, where he is co-Director of the Computational Perception Lab (CPL) and Director of the Center for Behavioral Imaging. He received his Ph.D. from CMU in 1995 and worked at the Cambridge Research Lab of DEC (and then Compaq) from 1995-2001, where he managed the computer vision research group. He received an NSF CAREER award in 2001 and a Raytheon Faculty Fellowship from Georgia Tech in 2005. He and his students have received best student paper awards at ICML 2005, BMVC 2010, Mobihealth 2014, and Face and Gesture 2015, and a 2013 Method of the Year Award from the journal Nature Methods. Dr. Rehg serves on the Editorial Board of the Intl. J. of Computer Vision, and he served as the Program co-Chair for ACCV 2012 and General co-Chair for CVPR 2009, and will serve as Program co-Chair for CVPR 2017. He has authored more than 100 peer-reviewed scientific papers and holds 25 issued US patents. His research interests include computer vision, machine learning, pattern recognition, and robot perception. Dr. Rehg is the lead PI on an NSF Expedition to develop the science and technology of Behavioral Imaging, the measurement and analysis of social and communicative behavior using multi-modal sensing, with applications to developmental disorders such as autism. He also serves as the Deputy Director of the NIH Center of Excellence on Mobile Sensor Data-to-Knowledge (MD2K).</p>
							<hr style="color: #eb4947; width: 90%; size: 1.5px;" />					


						</section>

				</div>
			</section>

		<!-- Footer -->
		<div id="footer">
			<div class="container">
					<img src="images/mdotLogoFade.png" alt="" height="100px;" style="margin-bottom: 15px; display: block; margin-left: auto; margin-right: auto;" />
					<p class="copyright" style="margin-left:5%; margin-right:5%;">The mHealth Center for Discovery, Optimization & Translation of Temporally-Precise Interventions is supported by the National Institutes of Health's National Institute of Biomedical Imaging and Bioengineering through its Biomedical Technology Resource Centers Program.</p>
					<p class="copyright">&copy; MD2K. All rights reserved.</p>
			</div>
		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollgress.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
